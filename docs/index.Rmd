---
title: 'Predição de vida remanescente de motores a jato: Uma Abordagem de Aprendizado de Máquina'
author: "Tomás Silva"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: tibble
  word_document: default
editor_options: 
  chunk_output_type: console
---

```{r}

#library(reticulate)
#install.packages("remotes")
#remotes::install_github(sprintf("rstudio/%s", c("reticulate", "tensorflow", "keras")))
#install_miniconda()
#library(keras)
#install_keras()

#tensorflow::as_tensor("Hello World")

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(plyr)
library(dplyr)
library(tidyverse)
library(Hmisc)
library(Metrics)
library(randomForest)
library(gbm)
library(hash)
library(caret)
library(knitr)
library(PerformanceAnalytics)
library(nortest)
library(car)
library(neuralnet)
library(keras)
library(gridExtra)
```

# Carregamento e entendimento das bases de dados

Há 4 bases de treinamento, cada uma para uma condição de uso.

```{r}
train_file <- "Turbo fan dataset/CMaps/train_FD001.txt"
test_file <- "Turbo fan dataset/CMaps/test_FD001.txt"
RUL_file <- "Turbo fan dataset/CMaps/RUL_FD001.txt"

#Carregamento das base de dados em tibbles
train_df <- tibble(read.delim(train_file, header = FALSE, sep = " "))
test_df <- tibble(read.delim(test_file, header = FALSE, sep = " "))
y_test <- tibble(read.delim(RUL_file, header = FALSE, sep = " "))

#Criação de numeração para os dados de sensoriamento
sensor_names <- c("(Fan inlet temperature) (◦R)",
"(LPC outlet temperature) (◦R)",
"(HPC outlet temperature) (◦R)",
"(LPT outlet temperature) (◦R)",
"(Fan inlet Pressure) (psia)",
"(bypass-duct pressure) (psia)",
"(HPC outlet pressure) (psia)",
"(Physical fan speed) (rpm)",
"(Physical core speed) (rpm)",
"(Engine pressure ratio(P50/P2)",
"(HPC outlet Static pressure) (psia)",
"(Ratio of fuel flow to Ps30) (pps/psia)",
"(Corrected fan speed) (rpm)",
"(Corrected core speed) (rpm)",
"(Bypass Ratio) ",
"(Burner fuel-air ratio)",
"(Bleed Enthalpy)",
"(Required fan speed)",
"(Required fan conversion speed)",
"(High-pressure turbines Cool air flow)",
"(Low-pressure turbines Cool air flow)")

sensor_n <- c()
for (x in 1:21){
  new_sensor <- paste(c("s", x#, "_",sensor_names[x]
                        ), collapse = "")
  sensor_n <- append(sensor_n, new_sensor)
  }

sensors_dict <- hash(sensor_n,sensor_names)

#Alteração do nome das colunas do dataset
colnames <- c("engine_id", "cycles", "altitude", "mach", "tra", sensor_n)
colnames(train_df) <- colnames
colnames(test_df) <- colnames
```


```{r}
#Remoção das colunas sem dados
train <- train_df[,colSums(is.na(train_df)) < nrow(train_df)]
test <- test_df[,colSums(is.na(test_df)) < nrow(test_df)]
y_test <- y_test[,colSums(is.na(y_test)) < nrow(y_test)]

```

Adição da RUL à base de treinamento e de testes.

```{r}
#A base de treinamento possui dados dos sensores até a falha, ou seja,o maior ciclo presente no banco de dados é o ciclo em que a falha aconteceu. Logo, a RUL em cada instante é o maior ciclo registrado do motor subtraído do ciclo de cada instante:
train <- train %>% 
  group_by(engine_id) %>%
  mutate(RUL = max(cycles) - cycles) %>%
  ungroup()

#A base de testes possui apenas parte do ciclo de vida de cada motor, a real RUL de cada um após o último instante na base de testes está na base y_test.

engine_id <- 1:100
y_test <- y_test %>% 
  mutate(engine_id = engine_id) %>% 
  rename(True_RUL = V1)


test <- test %>%
  left_join(y_test, by = "engine_id") %>% 
  group_by(engine_id) %>%
  mutate(RUL1 = max(cycles) - cycles) %>%
  mutate(RUL = RUL1 + True_RUL) %>% 
  ungroup() %>% 
  select(-True_RUL, -RUL1)
  

```

### Estatísticas descritivas

```{r}
train_description <- as.data.frame(do.call(cbind, lapply(train, summary)))
test_description <- as.data.frame(do.call(cbind, lapply(test, summary)))

library(kableExtra)
train_description %>%
  select(-RUL, -engine_id) %>% 
  round(2) %>% 
  kbl(caption = "Estatísticas descritivas") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))


train_description <- 
  train_description %>% 
  filter(rownames(train_description) == "Median" | rownames(train_description) == "Min."| rownames(train_description) == "Max.") %>%
  rownames_to_column(var = "Statistics") %>%  
  pivot_longer(cols = -Statistics,names_to = "Sensor", values_to = "train_value") %>% 
  select(2,1,3) %>% 
  arrange(Sensor)

test_description <- 
  test_description %>% 
  filter(rownames(test_description) == "Median" | rownames(test_description) == "Min."| rownames(test_description) == "Max.") %>%
  rownames_to_column(var = "Statistics") %>%  
  pivot_longer(cols = -Statistics,names_to = "Sensor", values_to = "test_value") %>% 
  select(2,1,3) %>% 
  arrange(Sensor)

sensor_description <- merge(train_description, test_description, by=c("Sensor", "Statistics"))

#Há sensores que não apresentaram variação nas medições. Colunas serão removidas dos datasets:
summary(train)
train <- train %>% select(1:4,where(~ max(.x) - min(.x) !=0))

#Observação do comportamento do número máximo de ciclos de cada motor:
train %>% group_by(engine_id) %>% summarise(max_cycles = max(cycles)) %>% 
  ggplot()+
  geom_density(mapping = aes(x = max_cycles), color = "blue") +
  theme_light() +
  labs(title = "Densidade do número máximo de ciclos") +
  xlab("Máximo número de ciclos") +
  theme(plot.subtitle = element_text(hjust = 0.5))+
  scale_x_continuous(breaks = seq(120,380,20))
  
train %>% group_by(engine_id) %>% summarise(max_cycles = max(cycles)) %>% summary()

```

Observa-se que a maior parte (75%) dos motores teve número de ciclos inferior a 229.2, e o número mínimo é 128. Metade dos motores teve vida entre 177 e 229.2 ciclos

# Preparação dos dados

### Análise e seleção de atributos


Análise de correlação entre os sensores e dos sensores com a RUL, considerando um nível de significância de 5% :

```{r}
cor_train <- rcorr(as.matrix(train[5:length(train)]))
r_matrix <- cor_train$r
p_matrix <- cor_train$P
#cor_train <- cor(train[6:21], method = "pearson")

corrplot::corrplot(corr = r_matrix, method = "color", type = "upper", addCoef.col = "black", diag= F, addCoefasPercent = T, tl.col = "black", number.cex = 0.8, p.mat = p_matrix, sig.level = 0.05, insig = "pch")

```

O sensor 6 tem baixa (-0.13) correlação com a RUL, enquanto que os sensores 9 e 14 tem alta (0.96) correlação entre si. Eles são a (Physical core speed) e (Corrected core speed), o que indica que somente um deles pode ser suficiente para a criação do modelo.

Os sensores 6 e 14 serão removidos da base para simplificá-la:

```{r}
values(sensors_dict, keys = c("s9", "s14"))
train <- train %>% select(-s6, -s14)

colunas_treino <- colnames(train) #Vetor com as colunas presentes na base de treino após as reduçoes realizadas 
test <- test %>% select(all_of(colunas_treino))

```

Observação do comportamento dos dados dos sensores 
```{r}
lista_aleatoria <- sample.int(100,5,replace = F)

train_simplificada <- train %>% filter(engine_id %in% lista_aleatoria)
lista_plot <- list()
for (i in 5:(length(train_simplificada)-1)){
  s <- tibble()
  s <- train_simplificada %>% select(engine_id,i,length(train_simplificada)) %>% rename(sensor = 2)
  lista_plot[[paste0("plot", i)]] <- ggplot(data = s)+
    geom_line(mapping = aes(x = RUL, y = sensor, color = factor(engine_id)), show.legend = F)+
    scale_x_reverse()+
    theme_bw(base_size=8) +
    labs(y=paste("sensor",colnames(train_simplificada)[i]))
}

do.call("grid.arrange", c(lista_plot, top = "Dados dos sensores vs RUL"))
```

Nota-se que os sensores 2, 3, 4, 8, 9, 11,13, 15 e 17 tem comportamento crescente com o passar dos ciclos de funcionamento e, consequentemente, um aumento do seu valor está relacionado à redução da RUL. Já os sensores 7, 12, 20 e 21 possuem comportamento decrescente com a RUL. 


### Filtragem dos dados com base nas medianas móveis

```{r}
median_filter <- function(x, k=7){runmed(x,k)} #Median Filter

#base de treinamento
train_filtered <- ddply(train,.(engine_id),function(x) 
  { 
    sapply(x[,5:17],function(y) median_filter(y))
  })
train_filtered <- as_tibble(cbind(train[1:2], train_filtered[2:14], train[18]))

#base de teste
test_filtered <- ddply(test,.(engine_id),function(x) 
  { 
    sapply(x[,5:17],function(y) median_filter(y))
  })
test_filtered <- as_tibble(cbind(test[,1:2], test_filtered[2:14], test[18]))


#Visualização do comportamento dos sensores
train_simplificada <- train_filtered %>% filter(engine_id %in% lista_aleatoria)
lista_plot <- list()
for (i in 3:(length(train_simplificada)-1)){
  s <- tibble()
  s <- train_simplificada %>% select(engine_id,i,length(train_simplificada)) %>% rename(sensor = 2)
  lista_plot[[paste0("plot", i)]] <- ggplot(data = s)+
    geom_line(mapping = aes(x = RUL, y = sensor, color = factor(engine_id)), show.legend = F)+
    scale_x_reverse()+ 
    theme_bw(base_size=8) +
    labs(y=paste("sensor",colnames(train_simplificada)[i]))
}

do.call("grid.arrange", c(lista_plot, top = "Dados filtrados dos sensores vs RUL"))

#Visualização do comportamento dos dados do sensor 3 após a aplicação do filtro de medianas móveis
train_temp <-  train_filtered %>% 
  filter(engine_id==7) %>% 
  select(1,s3, RUL) %>% 
  mutate(sensor_filtered = s3, .keep = "unused")

train_temp <-  train %>% 
  filter(engine_id==7) %>% 
  select(s3) %>%
  mutate(sensor_unfiltered = s3, .keep = "unused") %>% 
  cbind(train_temp)
  
ggplot(data = train_temp,aes(x = RUL))+
    geom_line(mapping = aes(y = sensor_filtered, color = "sensor_filtered"),linewidth = 0.8)+
    geom_line(mapping = aes(y = sensor_unfiltered, color = "sensor_unfiltered"),linewidth = 0.5)+
    scale_color_manual(name = "Tipo de dados", values = c("sensor_filtered" = "blue", "sensor_unfiltered" = "red"))+
    scale_x_reverse()+
    labs(y="sensor values",title="sensor 3 - Filtered vs Unfiltered")+
    theme_bw(base_size=8)+
    theme(plot.title = element_text(hjust = 0.5),legend.position = "bottom", legend.direction = "horizontal")


```

Pode-se identificar que há, visualmente, menos ruído nos dados e vários “outliers” foram suavizados após a aplicação do filtro de medianas móveis.


### Padronização das bases de dados

```{r}
#Base de treinamento
mean <- lapply(train_filtered, mean)
std <- lapply(train_filtered, sd)
  
train_scaled <- as_tibble(scale(train_filtered,center = mean, scale = std))
train_scaled <- cbind(train_filtered[1], train_scaled[,2:15], train_filtered[16])
test_scaled <- as_tibble(scale(test_filtered,center = mean, scale = std))
test_scaled <- cbind(test_filtered[1], test_scaled[,2:15], test_filtered[16])

```



```{r}
lista_plot <- list()
for (i in 3:(length(train_scaled)-1)){
  s <- tibble()
  s <- train_scaled %>% select(i) %>% rename(sensor = 1)
  lista_plot[[paste0("plot", i)]] <- ggplot(data = s, aes(sensor))+
    geom_histogram(show.legend = FALSE)+
    theme_bw(base_size=8) +
    labs(x=paste("sensor",colnames(train_scaled)[i]))
}

do.call("grid.arrange", c(lista_plot, top = "Histograma dos dados dos sensores após padronização"))

```

O Histograma mostra que a variação dos dados se restrinjiu a uma faixa de valores de mesma grandeza, média 0 e desvio padrão 1.  

### Definição da função erro

```{r}

score <- function (y_true, y_pred, a1 = 13, a2 = 10){
            d <- y_pred - y_true
            n <- nrow(y_true)
            score <- 0
            for (i in d) {
              if(i<0){
                score <- score + exp(-i/a1) - 1
              } else {
                score <- score + exp(i/a2) - 1
              }
            }  
          score
          }

func_score <- function(y_true, y_pred, tipo = "treino"){
            list_scores <- list(round(score(y_true, y_pred),2),
                            round(mae(y_true, y_pred),2),
                            round(rmse(y_true, y_pred),2))
            if (tipo == "treino"){
            cat("Mean Absolute Error: ",list_scores[[2]],"\n",
                "Root Mean Squared Error: ", list_scores[[3]], sep = "")
            } else {
            cat("Score: ", list_scores[[1]],"\n",
                "Mean Absolute Error: ",list_scores[[2]],"\n",
                "Root Mean Squared Error: ", list_scores[[3]], sep = "")
            }
}

```

# Criação dos modelos supervisionados

### Preparação da base de testes

Somente as colunas usadas para o treinamento são mantidas. Além disso, só será usado a linha com o último ciclo monitorado para comparar a RUL predita com a RUL real.

```{r}
test_end_cycle <- test_scaled %>% 
  group_by(engine_id) %>%
  mutate(max = max(cycles)) %>% 
  ungroup() %>% 
  filter(cycles == max) %>% 
  select(-max, -engine_id)

```

Função para plotar os gráficos de comparação de resultados e de Histograma de Erros

```{r}
plot_results <- function(results_df, metodo = "Modelo base", stat = c("Critical", "Non Critical")){
  
lista_plot <- list()

df <- results_df %>% 
  filter(method == metodo) %>%
  filter(status %in% stat)


lista_plot[["Gráfico de comparação"]] <- df %>% 
  ggplot(mapping = aes(x = engine_id)) +
  geom_line(mapping = aes(y = y_true), linewidth = 0.7,linetype = 1, colour = "gray") + 
  geom_point(mapping = aes(y = y_true, colour = "True RUL"), shape = 22, fill = "blue") +
  geom_line(mapping = aes(y = y_pred),linewidth = 0.5, linetype = 3, colour = "gray") + 
  geom_point(mapping = aes(y = y_pred, colour = prediction_type)) + 
  labs(x = "engine id", y = "RUL - Cycles", title = "Gráfico (a) - Comparação de resultados")+
  theme_light() +
  scale_colour_manual(" ", values=c("#E69F00", "darkred", "blue"))+
  scale_y_continuous(limits = c(0, NA))+
  theme(legend.position = "bottom", legend.title = element_blank(), legend.key=element_blank(),plot.title = element_text(hjust = 0.5))


lista_plot[["Histograma de erros"]] <- df %>% 
  ggplot(mapping = aes( error)) +
  geom_histogram(show.legend = FALSE)+
  theme_bw(base_size=8)+
  labs(title = "Gráfico (b) - Histograma de erros")+
  theme_light() +
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_continuous(limits = ~ c(-1, 1) * max(abs(.x)))+
  labs (caption = paste0("Range de erros: ", round(min(df$error), 2), " a ",round(max(df$error), 2)))

do.call("grid.arrange", c(lista_plot, ncol = 2))
}

```

### Modelo de referência

```{r}
media_RUL <- train_scaled %>% group_by(engine_id) %>% summarise(max_RUL = max(RUL)) %>% summarise(mean = mean(max_RUL))
media_RUL <- as.integer(media_RUL)

train_mb <- train_filtered %>% mutate(RUL_pred = media_RUL - cycles) %>% mutate(RUL_pred = ifelse(RUL_pred <= 0, 0, RUL_pred)) %>% select(engine_id, RUL,RUL_pred)
func_score(train_mb$RUL,train_mb$RUL_pred)

test_mb <- test_filtered %>% mutate(RUL_pred = media_RUL - cycles) %>% mutate(RUL_pred = ifelse(RUL_pred <= 0, 0, RUL_pred)) %>% select(engine_id, RUL,RUL_pred)
func_score(test_mb$RUL,test_mb$RUL_pred)

y_test_mb_end <- test_mb %>% group_by(engine_id) %>%
  mutate(min = min(RUL)) %>% 
  ungroup() %>% 
  filter(RUL == min) %>% 
  select(engine_id, RUL,RUL_pred)
func_score(y_test_mb_end$RUL,y_test_mb_end$RUL_pred, "teste")

#Compilação dos resultados
results <- tibble()
results_mb <- tibble(engine_id = 1:100,
                  method = "Modelo base", 
                  y_true = y_test_mb_end$RUL, 
                  y_pred = y_test_mb_end$RUL_pred,
                  prediction_type = case_when(y_pred>y_true ~ "Late prediction",
                                              y_pred<y_true ~ "Early prediction"),
                  error = y_pred - y_true) %>%
  mutate(status = case_when(y_true < 50 ~ "Critical",y_true >= 50 ~ "Non Critical"))

results <- results_mb

plot_results(results, metodo = "Modelo base")

```

### Modelo de Random Forest

```{r}
#Treinamento do modelo e Importance Analysis
set.seed(12)
rf_fit <- randomForest(RUL~.-engine_id -cycles,data = train_scaled)
rf_fit
varImpPlot(rf_fit)
importance(rf_fit)

#Análise dos resultados da base de treinamento
y_train_rf <- predict(rf_fit)
y_train_true <- as.numeric(train_scaled$RUL)
func_score(y_train_true, y_train_rf)
 
train_rf <- train_scaled %>%  select(engine_id, RUL) %>% mutate(RUL_pred = y_train_rf)

engine_samples <- sample(1:100,3)
train_rf %>% filter(engine_id %in% engine_samples) %>% 
  ggplot(aes(x=RUL))+
  geom_line(aes(y=RUL,color = "RUL"))+
  geom_line(aes(y=RUL_pred,color = "RUL predicted"))+
  scale_x_reverse()+
  labs(x = NULL, title = "Random Forest - Base treinamento")+
  scale_colour_manual(" ", values=c("darkblue", "darkred"))+
  theme_bw()+
  theme(legend.position = "bottom",legend.title = element_blank(), legend.key=element_blank(),plot.title = element_text(hjust = 0.5))+
  facet_grid(rows = vars(engine_id), scales ="free")


#Análise dos resultados da base de teste - Completa
y_test_rf <- predict(rf_fit,test_scaled)
y_test_true <- as.numeric(test_scaled$RUL)
func_score(y_test_true,y_test_rf)


test_RUL_initial <- test_scaled %>% group_by(engine_id) %>% summarise(max = max(RUL)) %>% arrange(max) #Escolha de 3 motores dessa base para análise gráfica
engine_samples <- c(41,27,12)

test_scaled %>% 
  select(engine_id, RUL) %>% 
  mutate(RUL_pred = y_test_rf) %>% 
  filter(engine_id %in% engine_samples) %>% 
  ggplot(aes(x=RUL))+
  geom_line(aes(y=RUL, color = "RUL"))+
  geom_line(aes(y=RUL_pred,color = paste0("RUL predicted")))+
  scale_x_reverse()+
  labs(x = NULL, title = "Random Forest - Base de teste")+
  scale_colour_manual(" ", values=c("darkblue", "darkred"))+
  theme_bw()+
  theme(legend.position = "bottom",legend.title = element_blank(), legend.key=element_blank(),plot.title = element_text(hjust = 0.5))+
  facet_grid(rows = vars(engine_id), scales ="free")
 

#Análise dos resultados da base de teste - RUL último ciclo
y_test_rf_end <- predict(rf_fit,test_end_cycle)
y_test_true_end <- as.numeric(test_end_cycle$RUL)
func_score(y_test_true_end,y_test_rf_end, tipo = "teste")


#Compilação dos resultados
results_rf <- tibble(engine_id = 1:100,
                  method = "Random Forest", 
                  y_true = y_test_true_end, 
                  y_pred = y_test_rf_end,
                  prediction_type = case_when(y_pred>y_true ~ "Late prediction",
                                              y_pred<y_true ~ "Early prediction"),
                  error = y_pred - y_true
                  )%>%
  mutate(status = case_when(y_true < 50 ~ "Critical",y_true >= 50 ~ "Non Critical"))
 

results <- rbind(results, results_rf)

plot_results(results_rf, "Random Forest")

```

### Redes neurais - Time series

#### Função gerador

Criação de função de geração das bases de dados para formatá-la e prepará-la para uso no algoritmo do LSTM. Ver: <https://stackoverflow.com/questions/53357901/using-a-custom-r-generator-function-with-fit-generator-keras-r> <https://blogs.rstudio.com/ai/posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks/>

```{r}
data <- data.matrix(train_scaled[,])

generator <- function(data, lookback, delay, max_index, min_index,
                      shuffle = FALSE, batch_size, step, reset = FALSE) {

  # Definição das linhas a serem selecionadas
  if (is.null(max_index))
    max_index <- nrow(data) - delay  - lookback
  i <- min_index + lookback
  function() {
    if (shuffle) {
      rows <- sample(c((min_index+lookback):max_index), size = batch_size)
    } 
    else {
      if (i + batch_size >= max_index){
      rows <- c(i:max_index)
      i <<- min_index + lookback
      } else if (data[[i]] == data[[min(i+batch_size-1, max_index)]]){ 
      rows <- c(i:min(i+batch_size-1, max_index))
      i <<- i + step
      } else {
      engine_id <- data[[i]]
      max_index_id <- max(which(data[,1] == engine_id, arr.ind = T))
      rows <- c(i:min(i+batch_size-1, max_index,max_index_id))
      i <<- min(i+step, max_index, max_index_id+1)
      }
      #i <<- i + step
    }

    samples <- array(0, dim = c(length(rows),
                                1,
                                dim(data)[[-1]]-3))
    targets <- array(0, dim = c(length(rows)))
    
# Obtenção das amostras e targets
    for (j in 1:length(rows)) {
      indices <- seq(rows[[j]] - lookback,rows[[j]]-1,length.out = dim(samples)[[2]])
      samples[j,,] <- data[indices,3:15]
      targets[[j]] <- data[rows[[j]] + delay,ncol(data)]
    }           
    list(samples, targets)
  }
}

# Definição dos parâmetros do gerador
lookback <- 0
delay <- 0
batch_size <- 15
step <- 15



# Definição de parâmetros da rede neural
steps_per_epoch <- as.numeric(train_scaled %>%
  filter(engine_id <= 80) %>% 
  group_by(engine_id) %>%
  summarise(contagem = n()) %>%
  mutate(n_batches = ceiling(contagem/batch_size)) %>%
  ungroup() %>% 
  summarise(soma1 = sum(n_batches)))

val_steps <- as.numeric(train_scaled %>%
  filter(engine_id > 80) %>% 
  group_by(engine_id) %>%
  summarise(contagem = n()) %>%
  mutate(n_batches = ceiling(contagem/batch_size)) %>%
  ungroup() %>% 
  summarise(soma1 = sum(n_batches)))

test_steps <- as.numeric(test_scaled %>%
  group_by(engine_id) %>%
  summarise(contagem = n()) %>%
  mutate(n_batches = ceiling(contagem/batch_size)) %>%
  ungroup() %>% 
  summarise(soma1 = sum(n_batches)))

```

### Criação do modelo LSTM

```{r}
nodes = 60

lstm_model <- keras_model_sequential() %>% 
  layer_lstm(units = nodes, 
             input_shape = list(NULL, dim(data)[[-1]]-3), 
             dropout = 0.2, recurrent_dropout = 0.2,
             return_sequences = TRUE) %>% 
  layer_lstm(units = nodes, 
             dropout = 0.2, recurrent_dropout = 0.2,
             return_sequences = TRUE) %>%
  layer_lstm(units = nodes, 
             dropout = 0.2, recurrent_dropout = 0.2,
             return_sequences = TRUE) %>% 
  layer_dense(units = nodes, activation ="relu") %>% 
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = nodes, activation ="relu") %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1)

lstm_model %>% compile(
  optimizer = optimizer_adam(learning_rate = 0.02),
  loss = loss_mean_squared_error()
  )

summary(lstm_model)
```

Treinamento do modelo

```{r}
# Gerador da base de treinamento (Motores 1 - 80 da base de treino)
train_gen <- generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = max(which(data[,1] == 80, arr.ind = T)),
  shuffle = FALSE,
  step = step, 
  batch_size = batch_size)

# Gerador da base de validação (Motores 81 - 100 da base de treino)
val_gen <- generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = max(which(data[,1] == 80, arr.ind = T))+1,
  max_index = max(which(data[,1] == 100, arr.ind = T)),
  shuffle = FALSE,
  step = step,
  batch_size = batch_size
)


history <- lstm_model %>% fit_generator(
  train_gen,
  steps_per_epoch = steps_per_epoch,
  epochs = 25,
  verbose = 1,
  validation_data = val_gen,
  validation_steps = val_steps
)
```

Análise do modelo treinado

```{r}
# Gerador da base de treinamento (Motores 1 - 80 da base de treino)
train_gen <- generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = max(which(data[,1] == 80, arr.ind = T)),
  shuffle = FALSE,
  step = step, 
  batch_size = batch_size)

y_train_lstm <- predict_generator(
  lstm_model,
  train_gen,
  steps = steps_per_epoch-1)


y_train_true <- train_scaled %>% 
  filter(engine_id <= 80) %>% 
  select(engine_id, RUL)

n_rows <- min(dim(y_train_lstm)[1], dim(y_train_true)[1])
train_LSTM_RUL <- as_tibble(cbind(y_train_true[1:n_rows,], 
                                  RUL_pred = y_train_lstm[1:n_rows,1,1]))

engine_samples <- c(41,27,12)
train_LSTM_RUL %>% filter(engine_id %in% engine_samples) %>% 
  ggplot(aes(x=RUL))+
  geom_line(aes(y=RUL, color = "RUL"))+
  geom_line(aes(y=RUL_pred,color = paste0("RUL predicted")))+
  scale_x_reverse()+
  labs(x = NULL, title = "LSTM - Base de treinamento")+
  scale_colour_manual(" ", values=c("darkblue", "darkred"))+
  theme_bw()+
  theme(legend.position = "bottom",legend.title = element_blank(), legend.key=element_blank(),plot.title = element_text(hjust = 0.5))+
  facet_grid(rows = vars(engine_id), scales ="free")
  
func_score(as.numeric(train_LSTM_RUL$RUL), as.numeric(train_LSTM_RUL$RUL_pred))
```

Aplicação do modelo na base de teste

```{r}
# Gerador da base de teste 
data_test <- data.matrix(test_scaled[,])

test_gen <- generator(
  data_test,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = NULL,
  shuffle = FALSE,
  step = step,
  batch_size = batch_size
)

y_test_lstm <- predict_generator(
  lstm_model,
  test_gen,
  steps = test_steps)


y_test_true <- test_scaled %>% select(engine_id, RUL)
dim(y_test_lstm)[1] == dim(y_test_true)[1]
n_rows <- min(dim(y_test_lstm)[1], dim(y_test_true)[1])
test_LSTM_RUL <- as_tibble(cbind(y_test_true[1:n_rows,], RUL_pred = y_test_lstm[1:n_rows,1,1]))

#Análise dos resultados da base de teste - RUL último ciclo
y_test_LSTM_end <- test_LSTM_RUL %>% 
  group_by(engine_id) %>% 
  mutate(min = min(RUL), check = RUL - min) %>% 
  filter(check == 0) 

y_test_true_end <- as.numeric(test_end_cycle$RUL)
func_score(y_test_LSTM_end$RUL,y_test_LSTM_end$RUL_pred, tipo = "teste")


```

### Lstm model (2)

RUL alvo modificada de uma função  linear para uma linear por partes.

```{r}
lstm_model2 <- keras_model_sequential() %>% 
  layer_lstm(units = nodes, 
             input_shape = list(NULL, dim(data)[[-1]]-3), 
             dropout = 0.2, recurrent_dropout = 0.2,
             return_sequences = TRUE) %>% 
  layer_lstm(units = nodes, 
             dropout = 0.2, recurrent_dropout = 0.2,
             return_sequences = TRUE) %>%
  layer_lstm(units = nodes, 
             dropout = 0.2, recurrent_dropout = 0.2,
             return_sequences = TRUE) %>% 
  layer_dense(units = nodes, activation ="relu") %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = nodes, activation ="relu") %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 1)

lstm_model2 %>% compile(
  optimizer = optimizer_adam(learning_rate = 0.02),
  loss = loss_mean_squared_error()
  )

summary(lstm_model2)
```

Treinamento do modelo

```{r}
train_scaled2 <- train_scaled %>% mutate(RUL = ifelse(RUL >= 130, 130, RUL))
                                           
data2 <- data.matrix(train_scaled2[,])
# Gerador da base de treinamento (Motores 1 - 80 da base de treino)
train_gen2 <- generator(
  data2,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = max(which(data[,1] == 80, arr.ind = T)),
  shuffle = FALSE,
  step = step, 
  batch_size = batch_size
)

# Gerador da base de validação (Motores 81 - 100 da base de treino)
val_gen2 <- generator(
  data2,
  lookback = lookback,
  delay = delay,
  min_index = max(which(data[,1] == 80, arr.ind = T))+1,
  max_index = max(which(data[,1] == 100, arr.ind = T)),
  shuffle = FALSE,
  step = step,
  batch_size = batch_size
)  


history2 <- lstm_model2 %>% fit_generator(
  train_gen2,
  steps_per_epoch = steps_per_epoch,
  epochs = 25,
  verbose = 1,
  validation_data = val_gen2,
  validation_steps = val_steps
)
```

Análise do modelo treinado


```{r}
train_gen2 <- generator(
  data2,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = max(which(data[,1] == 80, arr.ind = T)),
  shuffle = FALSE,
  step = step, 
  batch_size = batch_size
)


y_train_lstm2 <- predict_generator(
  lstm_model2,
  train_gen2,
  steps = steps_per_epoch-1)


#Check de consistência da quantidade de variáveis preditas
y_train_true <- train_scaled2 %>% filter(engine_id <= 80) %>% select(engine_id, RUL)
n_rows <- min(dim(y_train_lstm2)[1], dim(y_train_true)[1])

train_LSTM_RUL2 <- as_tibble(cbind(y_train_true[1:n_rows,], RUL_pred = y_train_lstm2[1:n_rows,1,1]))

engine_samples <- c(41,27,12)
train_LSTM_RUL2 %>% filter(engine_id %in% engine_samples) %>% 
  ggplot(aes(x=RUL))+
  geom_line(aes(y=RUL, color = "RUL"))+
  geom_line(aes(y=RUL_pred,color = paste0("RUL predicted")))+
  scale_x_reverse(breaks = seq(250,0,-20))+
  scale_y_continuous(limits = c(0,250))+
  labs(x = NULL, title = "LSTM - Base de treinamento")+
  scale_colour_manual(" ", values=c("darkblue", "darkred"))+
  theme_bw()+
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        legend.key=element_blank(),
        plot.title = element_text(hjust = 0.5))+
  facet_grid(rows = vars(engine_id))

func_score(as.numeric(train_LSTM_RUL2$RUL), as.numeric(train_LSTM_RUL2$RUL_pred))
```

Aplicação do modelo na base de teste

```{r}
test_gen <- generator(
  data_test,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = NULL,
  shuffle = FALSE,
  step = step,
  batch_size = batch_size
)

y_test_lstm2 <- predict_generator(
  lstm_model2,
  test_gen,
  steps = test_steps)


y_test_true <- test_scaled %>% select(engine_id, RUL)
dim(y_test_lstm2)[1] == dim(y_test_true)[1]
n_rows <- min(dim(y_test_lstm2)[1], dim(y_test_true)[1])

test_LSTM_RUL2 <- as_tibble(cbind(y_test_true[1:n_rows,], RUL_pred = y_test_lstm2[1:n_rows,1,1]))

#Análise dos resultados da base de teste - RUL último ciclo
y_test_LSTM_end2 <- test_LSTM_RUL2 %>% 
  group_by(engine_id) %>% 
  mutate(min = min(RUL), check = RUL - min) %>% 
  filter(check == 0) 

func_score(y_test_LSTM_end2$RUL,y_test_LSTM_end2$RUL_pred, tipo = "teste")

```

# Compilação dos resultados

```{r}
#O conjunto de observações em que a RUL real é inferior a 50 ciclos é considerado como o conjunto crítico em que um algoritmo de predição de vida remanescente precisa ser mais preciso, já que são ativos em estado de falha iminente.

results_lstm <- tibble(engine_id = 1:100,
                  method = "LSTM 1", 
                  y_true = y_test_LSTM_end$RUL, 
                  y_pred = y_test_LSTM_end$RUL_pred,
                  prediction_type = case_when(y_pred>y_true ~ "Late prediction",
                                              y_pred<y_true ~ "Early prediction"),
                  error = y_pred - y_true
                  ) %>% 
   mutate(status = case_when(y_true < 50 ~ "Critical",y_true >= 50 ~ "Non Critical"))

results_lstm2 <- tibble(engine_id = 1:100,
                  method = "LSTM 2", 
                  y_true = y_test_LSTM_end2$RUL, 
                  y_pred = y_test_LSTM_end2$RUL_pred,
                  prediction_type = case_when(y_pred>y_true ~ "Late prediction",
                                              y_pred<y_true ~ "Early prediction"),
                  error = y_pred - y_true
                  )  %>% 
  mutate(status = case_when(y_true < 50 ~ "Critical",y_true >= 50 ~ "Non Critical"))

results <- rbind(results, results_lstm,results_lstm2)

plot_results(results,  "LSTM 1")
plot_results(results, "LSTM 2")

results <- results %>% mutate(status = case_when(y_true < 50 ~ "Critical",
                                                 y_true >= 50 ~ "Non Critical"))
results_critical <- results %>% filter(status == "Critical") 

```


### Histograma de erros - Motores críticos

```{r}
hist_list <- list()
methods <- c("Modelo base", "Random Forest", "LSTM 1", "LSTM 2")

for (metodo in methods){
  df <- results_critical %>% filter(method == metodo)
  hist_list[[paste0("Histograma de erros - ", metodo)]] <- df %>% 
  ggplot(mapping = aes( error)) +
  geom_histogram(show.legend = FALSE, binwidth = 5)+
  theme_bw(base_size=8)+
  labs(subtitle = df$method)+
  theme_light() +
  theme(plot.subtitle = element_text(hjust = 0.5))+
  scale_x_continuous(limits = ~ c(-1, 1) * max(abs(.x)), breaks = seq(-70,70,10))+
  scale_y_continuous(breaks=seq(1,11,2)) +
  coord_cartesian(ylim = c(0,11), xlim=c(-75,75))
  }

do.call("grid.arrange", c(hist_list, top = "Histograma dos erros"))

```

### Resultados finais

```{r}

df <- tibble()

#Resultados para todos os motores
for (metodo in methods) {
  df <- results %>% filter(method == metodo)
  print(noquote(""))
  print(paste0("Para o método ", metodo, ", os resultados foram:"))
  func_score(df$y_true,df$y_pred, tipo = "teste")
}

#Resultados para os motores críticos
for (metodo in methods) {
  df <- results_critical %>% filter(method == metodo)
  print(noquote(""))
  print(paste0("Para o método ", metodo, ", os resultados foram:"))
  func_score(df$y_true,df$y_pred, tipo = "teste")
}

```

Os algoritmos de aprendizado de máquina  tiveram redução tanto do RMSE quanto do Score-s em relação ao modelo de referência.  

Dessa forma, este estudo mostra que os modelos de aprendizado de máquina poderiam ser ferramentas úteis para o direcionamento do momento mais adequado de atuação preventiva, levando não somente a redução de custos com corretivas, como também de custos com manutenções desnecessárias.